## 大数据常用命令集合



### 文件分发给其它节点   scp 

``` shell
scp -r xxx/xxx node2:xxx/xxx

[root@node1 server]# scp /etc/profile node3:/etc/

```




### Zookeeper
```shell
# zookeeper服务
	zkServer.sh start
	zkServer.sh status
	zkServer.sh stop
# zookeeper client
	zkCli.sh -server nod1:2181
	quit # 退出
```



### 查看java相关的进程

``` shell
jps
[root@node1 server]# jps
13952 JobHistoryServer
8321 QuorumPeerMain
14098 Jps
13267 DataNode
13622 NodeManager
13133 NameNode
13518 ResourceManager
[root@node1 server]# 

```



### Hadoop

#### 单节点逐个启动

``` shell
在node1主机上使用以下命令启动HDFS NameNode：
	hadoop-daemon.sh start namenode

在node1、node2、node3三台主机上，分别使用以下命令启动HDFS DataNode：
	hadoop-daemon.sh start datanode
	
在node1主机上使用以下命令启动YARN ResourceManager：
	yarn-daemon.sh  start resourcemanager
	
在node1、node2、node3三台主机上使用以下命令启动YARN nodemanager：
	yarn-daemon.sh start nodemanager
```

#### 单节点逐个停止

``` shell
只需要把命令中的start改为stop即可。
```



#### 脚本一键启动 或 停止 

##### 启动/停止HDFS

``` shell
start-dfs.sh
stop-dfs.sh
```



##### 启动/停止Yarn

``` shell
start-yarn.sh
stop-yarn.sh
```



##### 启动/停止历史任务服务进程

``` shell
mr-jobhistory-daemon.sh start historyserver
mr-jobhistory-daemon.sh stop historyserver

```



#### 一键启动、停止HDFS 和 yarn 

**注意** ： 这两个命令可以一键启动HDFS和 YARN , 但是无法启动 启动历史任务服务进程 。

``` shell
Start-all.sh  
stop-all.sh
```



#### hadoop

##### hadoop fs -put 

将文件上传到HDFS的根目录

``` shell
hadoop fs -put a.txt  /
```



##### hadoop checknative

查看当前的hadoop 支持的压缩算法

``` shell
[root@node1 data]# hadoop checknative
21/01/06 16:59:29 INFO bzip2.Bzip2Factory: Successfully loaded & initialized native-bzip2 library system-native
21/01/06 16:59:29 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
Native library checking:
hadoop:  true /export/server/hadoop-2.7.5/lib/native/libhadoop.so.1.0.0
zlib:    true /lib64/libz.so.1
snappy:  true /lib64/libsnappy.so.1
lz4:     true revision:99
bzip2:   true /lib64/libbz2.so.1
openssl: false Cannot load libcrypto.so (libcrypto.so: 无法打开共享对象文件: 没有那个文件或目录)!
[root@node1 data]# 

```



#### hdfs 命令



Hadoop提供了文件系统的shell命令行客户端，使用方法如下：

``` shell
hadoop  fs  <args>
```



##### args:

| **选项名称**   | **使用格式**                                                 | **含义**                   |
| -------------- | ------------------------------------------------------------ | -------------------------- |
| -ls            | -ls <路径>                                                   | 查看指定路径的当前目录结构 |
| -lsr           | -lsr <路径>                                                  | 递归查看指定路径的目录结构 |
| -du            | -du <路径>                                                   | 统计目录下个文件大小       |
| -dus           | -dus <路径>                                                  | 汇总统计目录下文件(夹)大小 |
| -count         | -count [-q] <路径>                                           | 统计文件(夹)数量           |
| -mv            | -mv <源路径> <目的路径>                                      | 移动                       |
| -cp            | -cp <源路径> <目的路径>                                      | 复制                       |
| -rm            | -rm [-skipTrash] <路径>                                      | 删除文件/空白文件夹        |
| -rmr           | -rmr [-skipTrash] <路径>                                     | 递归删除                   |
| -put           | -put <多个linux上的文件> <hdfs路径>                          | 上传文件                   |
| -copyFromLocal | -copyFromLocal <多个linux上的文件> <hdfs路径>                | 从本地复制                 |
| -moveFromLocal | -moveFromLocal <多个linux上的文件> <hdfs路径>                | 从本地移动                 |
| -getmerge      | -getmerge <源路径> <linux路径>                               | 合并到本地                 |
| -cat           | -cat <hdfs路径>                                              | 查看文件内容               |
| -text          | -text <hdfs路径>                                             | 查看文件内容               |
| -copyToLocal   | -copyToLocal [-ignoreCrc] [-crc] [hdfs源路径] [linux目的路径] | 从本地复制                 |
| -moveToLocal   | -moveToLocal [-crc] <hdfs源路径> <linux目的路径>             | 从本地移动                 |
| -mkdir         | -mkdir <hdfs路径>                                            | 创建空白文件夹             |
| -touchz        | -touchz <文件路径>                                           | 创建空白文件               |
| -stat          | -stat [format] <路径>                                        | 显示文件统计信息           |
| -tail          | -tail [-f] <文件>                                            | 查看文件尾部信息           |
| -chmod         | -chmod [-R] <权限模式> [路径]                                | 修改权限                   |
| -chown         | -chown [-R] [属主][:[属组]] 路径                             | 修改属主                   |
| -chgrp         | -chgrp [-R] 属组名称 路径                                    | 修改属组                   |
| -help          | -help [命令选项]                                             | 帮助                       |

##### 安全模式操作命令

``` shell
hdfs  dfsadmin -safemode  get #查看安全模式状态
hdfs  dfsadmin -safemode  enter #进入安全模式
hdfs  dfsadmin -safemode  leave #离开安全模式

hadoop  dfsadmin -safemode  get #查看安全模式状态
hadoop  dfsadmin -safemode  enter #进入安全模式
hadoop  dfsadmin -safemode  leave #离开安全模式
```

