## 大数据常用命令集合



### 文件分发给其它节点   scp 

``` shell
scp -r xxx/xxx node2:xxx/xxx

[root@node1 server]# scp /etc/profile node3:/etc/

```




### Zookeeper
```shell
# zookeeper服务
	zkServer.sh start
	zkServer.sh status
	zkServer.sh stop
# zookeeper client
	zkCli.sh -server nod1:2181
	quit # 退出
```



### 查看java相关的进程

``` shell
jps
[root@node1 server]# jps
13952 JobHistoryServer
8321 QuorumPeerMain
14098 Jps
13267 DataNode
13622 NodeManager
13133 NameNode
13518 ResourceManager
[root@node1 server]# 

```



### Hadoop

#### 单节点逐个启动

``` shell
在node1主机上使用以下命令启动HDFS NameNode：
	hadoop-daemon.sh start namenode

在node1、node2、node3三台主机上，分别使用以下命令启动HDFS DataNode：
	hadoop-daemon.sh start datanode
	
在node1主机上使用以下命令启动YARN ResourceManager：
	yarn-daemon.sh  start resourcemanager
	
在node1、node2、node3三台主机上使用以下命令启动YARN nodemanager：
	yarn-daemon.sh start nodemanager
```

#### 单节点逐个停止

``` shell
只需要把命令中的start改为stop即可。
```



#### 脚本一键启动 或 停止 

##### 启动/停止HDFS

``` shell
start-dfs.sh
stop-dfs.sh
```



##### 启动/停止Yarn

``` shell
start-yarn.sh
stop-yarn.sh
```



##### 启动/停止历史任务服务进程

``` shell
mr-jobhistory-daemon.sh start historyserver
mr-jobhistory-daemon.sh stop historyserver

```



#### 一键启动、停止HDFS 和 yarn 

**注意** ： 这两个命令可以一键启动HDFS和 YARN , 但是无法启动 启动历史任务服务进程 。

``` shell
Start-all.sh  
stop-all.sh
```



#### hadoop

##### hadoop fs -put 

将文件上传到HDFS的根目录

``` shell
hadoop fs -put a.txt  /
```



##### hadoop checknative

查看当前的hadoop 支持的压缩算法

``` shell
[root@node1 data]# hadoop checknative
21/01/06 16:59:29 INFO bzip2.Bzip2Factory: Successfully loaded & initialized native-bzip2 library system-native
21/01/06 16:59:29 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
Native library checking:
hadoop:  true /export/server/hadoop-2.7.5/lib/native/libhadoop.so.1.0.0
zlib:    true /lib64/libz.so.1
snappy:  true /lib64/libsnappy.so.1
lz4:     true revision:99
bzip2:   true /lib64/libbz2.so.1
openssl: false Cannot load libcrypto.so (libcrypto.so: 无法打开共享对象文件: 没有那个文件或目录)!
[root@node1 data]# 

```



